{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Training and Test Dataset for RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import gdal\n",
    "import ogr        # to read vector files\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage.segmentation import quickshift\n",
    "import time\n",
    "from skimage.segmentation import slic\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the map include all the bands (2-7) - we can clip the study of area\n",
    "# this map has loaded in QGIS\n",
    "data_path = 'D:/desktop/out_qgis/clip_merged.tif'\n",
    "data_set = gdal.Open(data_path)\n",
    "nRows = data_set.RasterYSize\n",
    "nCols = data_set.RasterXSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lctype</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>water</td>\n",
       "      <td>POINT (619702.306 4532704.428)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>water</td>\n",
       "      <td>POINT (628207.399 4537176.178)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>water</td>\n",
       "      <td>POINT (645173.745 4539894.301)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>water</td>\n",
       "      <td>POINT (662359.295 4495790.569)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>water</td>\n",
       "      <td>POINT (651486.804 4494913.755)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>bare_land</td>\n",
       "      <td>POINT (620777.773 4497245.532)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>bare_land</td>\n",
       "      <td>POINT (627156.593 4500051.336)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>bare_land</td>\n",
       "      <td>POINT (610513.572 4495130.218)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>bare_land</td>\n",
       "      <td>POINT (603340.139 4495590.546)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>bare_land</td>\n",
       "      <td>POINT (595952.983 4500117.097)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lctype                        geometry\n",
       "0       water  POINT (619702.306 4532704.428)\n",
       "1       water  POINT (628207.399 4537176.178)\n",
       "2       water  POINT (645173.745 4539894.301)\n",
       "3       water  POINT (662359.295 4495790.569)\n",
       "4       water  POINT (651486.804 4494913.755)\n",
       "..        ...                             ...\n",
       "61  bare_land  POINT (620777.773 4497245.532)\n",
       "62  bare_land  POINT (627156.593 4500051.336)\n",
       "63  bare_land  POINT (610513.572 4495130.218)\n",
       "64  bare_land  POINT (603340.139 4495590.546)\n",
       "65  bare_land  POINT (595952.983 4500117.097)\n",
       "\n",
       "[66 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we read the shapefile which has been obtaind by separating training data (points were allocated as water, urban, forest ... \n",
    "# to identify the number of land use/Land cover) in QGIS\n",
    "gdf = gpd.read_file('D:/desktop/out_qgis/truth_data_subset.shp')\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names ['water' 'vegetation' 'urban' 'bare_land']\n"
     ]
    }
   ],
   "source": [
    "# Identify the name of classes we have\n",
    "class_names = gdf['lctype'].unique()\n",
    "print('Class names', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class ids [1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# Here give number to each class_names\n",
    "# add 1 to start 1 index instead of 0 index\n",
    "class_ids = np.arange(class_names.size) + 1\n",
    "print('Class ids', class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lctype</th>\n",
       "      <th>geometry</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>water</td>\n",
       "      <td>POINT (619702.306 4532704.428)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>water</td>\n",
       "      <td>POINT (628207.399 4537176.178)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>water</td>\n",
       "      <td>POINT (645173.745 4539894.301)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>water</td>\n",
       "      <td>POINT (662359.295 4495790.569)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>water</td>\n",
       "      <td>POINT (651486.804 4494913.755)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lctype                        geometry  id\n",
       "0  water  POINT (619702.306 4532704.428)   1\n",
       "1  water  POINT (628207.399 4537176.178)   1\n",
       "2  water  POINT (645173.745 4539894.301)   1\n",
       "3  water  POINT (662359.295 4495790.569)   1\n",
       "4  water  POINT (651486.804 4494913.755)   1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a column \n",
    "# build DataFrame with the id column\n",
    "gdf['id'] = gdf['lctype'].map(dict(zip(class_names, class_ids)))\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdf shape (66, 3) training shape (46, 3) test shape (20, 3)\n"
     ]
    }
   ],
   "source": [
    "# create and separate Train and Test dataset\n",
    "gdf_train = gdf.sample(frac=0.7)\n",
    "gdf_test = gdf.drop(gdf_train.index)\n",
    "print('gdf shape', gdf.shape, 'training shape', gdf_train.shape, 'test shape', gdf_test.shape)\n",
    "# to save (we get a name with shp format (e.g:Train.shp) in the folder)\n",
    "gdf_train.to_file('D:/desktop/out_qgis/Train.shp')\n",
    "gdf_test.to_file('D:/desktop/out_qgis/Test.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Rasterize Shapefile Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Training data built in the previous phase\n",
    "train_path = 'D:/desktop/out_qgis/Train.shp'\n",
    "train_data = ogr.Open(train_path)\n",
    "layer = train_data.GetLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 0 max 4 mean 2.5999347223001128e-05\n"
     ]
    }
   ],
   "source": [
    "# Create a memory raster to rasterize into\n",
    "driver = gdal.GetDriverByName('MEM')   # MEM = memory\n",
    "# when using 'MEM', to Create target dataset, we do not need to identify an address so just give '' empty\n",
    "# 1 is the number of band\n",
    "target_data = driver.Create('', data_set.RasterXSize, data_set.RasterYSize, 1, gdal.GDT_UInt16)    # GDT_UInt16 = dataType\n",
    "target_data.SetGeoTransform(data_set.GetGeoTransform())\n",
    "target_data.SetProjection(data_set.GetProjection())\n",
    "# rasterize \n",
    "#options = ['ATTRIBUTE=id']\n",
    "gdal.RasterizeLayer(target_data, [1], layer,  options = ['ATTRIBUTE=id'])    # [1] = num of bands\n",
    "\n",
    "data1 = target_data.GetRasterBand(1).ReadAsArray()\n",
    "print('min', data1.min(), 'max', data1.max(), 'mean', data1.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice: to specify target dataset, the max should be equal the number of Classes (here the num of classes was 4)\n",
    "\n",
    "if the data1.max became 255 is wrong and we do'nt get the desired result\n",
    "\n",
    "Also, it is very essential to determine options=['ATTRIBUTE=id'] in gdal.RasterizeLayer because this phase will show data1.max\n",
    "correctly, without this, we would get wrong result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3- Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between Slic and Quickshift is that slic is faster than quickshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bands 6 rows 1777 columns 2619\n"
     ]
    }
   ],
   "source": [
    "# load the main map (include all bands (2-7)) in order to get band's number\n",
    "data = 'D:/desktop/out_qgis/clip_merged.tif'\n",
    "\n",
    "driverTiff = gdal.GetDriverByName('GTiff')\n",
    "study_ds = gdal.Open(data)\n",
    "nBands = study_ds.RasterCount\n",
    "\n",
    "band_data = []\n",
    "print('bands', study_ds.RasterCount, 'rows', study_ds.RasterYSize, 'columns', study_ds.RasterXSize)\n",
    "\n",
    "for i in range(1, nBands+1):\n",
    "    band = study_ds.GetRasterBand(i).ReadAsArray()    # To convert as an array\n",
    "    band_data.append(band)\n",
    "\n",
    "# by dstack, we reshape array 2D to 3D ->  (rows, columns, bands)\n",
    "band_data = np.dstack(band_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1777, 2619, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "band_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale band data\n",
    "img = exposure.rescale_intensity(band_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment complete\n"
     ]
    }
   ],
   "source": [
    "# do segmentation with slic and quickshift (slic is faster than quickshift)\n",
    "segments = slic(img, n_segments=500000, compactness=0.1)\n",
    "#segments = quickshift(img,ratio=0.99, max_dist=5, convert2lab=False)\n",
    "print('segment complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save segments to raster\n",
    "SegmentsOutput = 'D:/desktop/out_qgis/segments_final.tif'   \n",
    "\n",
    "segments_data = driverTiff.Create(SegmentsOutput, study_ds.RasterXSize, study_ds.RasterYSize,\n",
    "                               1, gdal.GDT_Float32)   # 1 = number of band ,  dtype = gdal.GDT_Float32\n",
    "segments_data.SetGeoTransform(study_ds.GetGeoTransform())\n",
    "segments_data.SetProjection(study_ds.GetProjectionRef())\n",
    "segments_data.GetRasterBand(1).WriteArray(segments)\n",
    "segments_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4- Get Statistics for Image Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we identified the number of segment's pixels and bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_features(segment_pixels):\n",
    "    features = []\n",
    "    npixels, nbands = segment_pixels.shape\n",
    "    for b in range(nbands):\n",
    "        stats = scipy.stats.describe(segment_pixels[:, b])  \n",
    "        band_stats = list(stats.minmax) + list(stats)[2:]\n",
    "        if npixels == 1:\n",
    "            # in this case the variance = nan, change it 0.0\n",
    "            band_stats[3] = 0.0\n",
    "        features += band_stats\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group pixels of segment_ids\n",
    "obj_start = time.time()\n",
    "# for each of segments, we have an id, an object and an object_id\n",
    "segment_ids = np.unique(segments)   # segment_id has the id for each segment\n",
    "objects = []\n",
    "object_ids = []\n",
    "\n",
    "for id in segment_ids:\n",
    "    segment_pixels = img[segments == id]         # img is 3D (rows, columns, channels)\n",
    "    print('pixels for id', id, segment_pixels.shape)\n",
    "    # every object has feature which come from segment's feature \n",
    "    object_features = segment_features(segment_pixels)\n",
    "    # object has data that correspond to each segment\n",
    "    objects.append(object_features)    # object is needed for training data\n",
    "    object_ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created 25048 objects with 36 variables in 788.4850730895996 second\n"
     ]
    }
   ],
   "source": [
    "print('created', len(objects), 'objects with', len(objects[0]), 'variables in', time.time()-obj_start, 'second')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Assign Classification to Image Segments for object based Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class value [1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "# we read target dataset in an array\n",
    "ground_truth = target_data.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "# class value should be numbered from 1 to the num of classes\n",
    "classes = np.unique(ground_truth)[1:]     # we do not have 0 so [1:] means upper than 0\n",
    "print('class value', classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training segment for class 1 : 10\n",
      "Training segment for class 2 : 9\n",
      "Training segment for class 3 : 15\n",
      "Training segment for class 4 : 12\n"
     ]
    }
   ],
   "source": [
    "segments_per_class = {}\n",
    "for k in classes:\n",
    "    segments_of_class = segments[ground_truth == k]   # where ground_truth is equal to k in segments\n",
    "    # add segmets_of_class to dict\n",
    "    segments_per_class[k] = set(segments_of_class)\n",
    "    print('Training segment for class', k, ':', len(segments_of_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make sure that segments are not a multiple classes, or make sure each class has not more one class\n",
    "intersection = set()\n",
    "accum = set()\n",
    "\n",
    "for class_segments in segments_per_class.values():\n",
    "    # this code means any accum intersection with class_segments sould be added to intersection\n",
    "    intersection |= accum.intersection(class_segments)    \n",
    "    accum |= class_segments                               \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6- Random Forest Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- create training image\n",
    "train_img = np.copy(segments)\n",
    "# 2- need to treshold to identify maximum of segment value is\n",
    "threshold = train_img.max() + 1\n",
    "\n",
    "# loop for classes we have\n",
    "\n",
    "for k in classes:\n",
    "    class_label = threshold + k\n",
    "    # each segment sould be equal class_label\n",
    "    for segment_id in segments_per_class[k]:\n",
    "        train_img[train_img == segment_id] = class_label    # to change train_img to class_label\n",
    "\n",
    "train_img[train_img <= threshold] = 0\n",
    "train_img[train_img > threshold] -= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training objecs for class 1 : 10\n",
      "Training objecs for class 2 : 9\n",
      "Training objecs for class 3 : 14\n",
      "Training objecs for class 4 : 12\n"
     ]
    }
   ],
   "source": [
    "training_objects = []\n",
    "training_labels = []\n",
    "\n",
    "for k in classes:\n",
    "    class_train_object = [value for i, value in enumerate(objects) if segment_ids[i] in segments_per_class[k]]\n",
    "    # this code will show the repeat of class,\n",
    "    # for example, if we had 15 segment represented water, we would then get number of 3 that repeated 15 times\n",
    "    training_labels += [k] * len(class_train_object)\n",
    "    # add training_objects\n",
    "    training_objects += class_train_object\n",
    "    print('Training objecs for class', k, ':', len(class_train_object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Random Forest Classifier\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_jobs=-1)\n",
    "model.fit(training_objects, training_labels)\n",
    "print('Fitting Random Forest Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Classifications\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(objects)\n",
    "print('Predicting Classifications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction applied to numpy array\n"
     ]
    }
   ],
   "source": [
    "# copy of segments\n",
    "clf = np.copy(segments)\n",
    "# predict segment_id\n",
    "\n",
    "for segment_id, k in zip(segment_ids, predicted):\n",
    "    clf[clf == segment_id] = k\n",
    "    \n",
    "print('Prediction applied to numpy array')\n",
    "    \n",
    "# make a mask to show us where we have data and do not have data\n",
    "mask = np.sum(img, axis=2)\n",
    "mask[mask > 0.0] = 1.0\n",
    "mask[mask == 0.0] = -1.0\n",
    "clf = np.multiply(clf, mask)\n",
    "clf[clf < 0] = -9999.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and visualize classification data\n",
    "\n",
    "clf_ds = driverTiff.Create('D:/desktop/out_qgis/Classified.tif', study_ds.RasterXSize, study_ds.RasterYSize,\n",
    "                          1, gdal.GDT_Float32)\n",
    "clf_ds.SetGeoTransform(study_ds.GetGeoTransform())\n",
    "clf_ds.SetProjection(study_ds.GetProjectionRef())\n",
    "clf_ds.GetRasterBand(1).SetNoDataValue(-9999.0)\n",
    "clf_ds.GetRasterBand(1).WriteArray(clf)\n",
    "clf_ds = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7- Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'D:/desktop/out_qgis/clip_merged.tif'\n",
    "\n",
    "driverTiff = gdal.GetDriverByName('GTiff')\n",
    "data_set = gdal.Open(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 0 max 4 mean 9.239437442884698e-06\n"
     ]
    }
   ],
   "source": [
    "# Test data\n",
    "# This need for accuracy the model\n",
    "test_path = 'D:/desktop/out_qgis/Test.shp'\n",
    "test_data = ogr.Open(test_path)\n",
    "layer = test_data.GetLayer() \n",
    "\n",
    "driver = gdal.GetDriverByName('MEM') \n",
    "target_test = driver.Create('', data_set.RasterXSize, data_set.RasterYSize, 1, gdal.GDT_UInt16)    # GDT_UInt16 = dataType\n",
    "target_test.SetGeoTransform(data_set.GetGeoTransform())\n",
    "target_test.SetProjection(data_set.GetProjection())\n",
    "# rasterize \n",
    "gdal.RasterizeLayer(target_test, [1], layer,  options = ['ATTRIBUTE=id'])    # [1] = num of bands\n",
    "\n",
    "truth_data = target_test.GetRasterBand(1).ReadAsArray()\n",
    "print('min', truth_data.min(), 'max', truth_data.max(), 'mean', truth_data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6, 0, 0, 1],\n",
       "       [0, 3, 0, 1],\n",
       "       [0, 0, 8, 0],\n",
       "       [0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_data = gdal.Open('D:/desktop/out_qgis/Classified.tif')\n",
    "prediction = pred_data.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "# To find locations in truth where are not zero\n",
    "idx_nonzero = np.nonzero(truth_data)\n",
    "\n",
    "# confusion matrix\n",
    "cm = confusion_matrix(truth_data[idx_nonzero], prediction[idx_nonzero]) \n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 396x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "\n",
    "plt.figure(figsize=(5.5,4))\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.title('RF \\nAccuracy:{0:.3f}'.format(accuracy_score(truth_data[idx_nonzero], prediction[idx_nonzero])))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
